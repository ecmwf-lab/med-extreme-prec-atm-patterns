{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Copyright 1996- ECMWF.\n",
    "#\n",
    "# This software is licensed under the terms of the Apache Licence Version 2.0\n",
    "# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "# In applying this licence, ECMWF does not waive the privileges and immunities\n",
    "# granted to it by virtue of its status as an intergovernmental organisation\n",
    "# nor does it submit to any jurisdiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstr = 1000 # Number of bootstraps for assessing the statistical significance of the results\n",
    "\n",
    "# get the index values of the 5th, 95th and median number, when data are ordered (for the bootstraping)\n",
    "l_min = int(bootstr*5/100)\n",
    "l_max = int(bootstr*95/100)-1\n",
    "l_med = int(bootstr/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_loc = ''\n",
    "out_dir = ''\n",
    "\n",
    "era5_med = out_dir+'Med_LocalizedPatterns_Labels.nc'\n",
    "frcsts_med = out_dir+'Med_LocalizedPatterns_ForecastAllocations.nc'\n",
    "\n",
    "offset_days = 22 # days to offset before/after central date for getting \"DayMonth\" moving-window Patterns clim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data for 9 Mediterranean clusters\n",
    "era5_med = xr.open_dataarray(era5_med)\n",
    "frcsts_med = xr.open_dataarray(frcsts_med)\n",
    "frcsts_med = frcsts_med.assign_coords({'ClustersNumber': era5_med.ClustersNumber.values})\n",
    "\n",
    "cl_max = era5_med.max().values\n",
    "cl_all = list(range(cl_max+1))\n",
    "frcsts_med.name = era5_med.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis - auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting temporal flags based on different subsetting (used later on for climatological freqs)\n",
    "def temp_flagging(valid_dates, temp_subset):\n",
    "    \n",
    "    valid_dates = pd.to_datetime(valid_dates)\n",
    "    \n",
    "    if temp_subset == 'All':\n",
    "        temporal_flag = ['All']*len(valid_dates)\n",
    "    elif temp_subset == 'HalfYear':\n",
    "        temporal_flag = (valid_dates.month%12 + 3)//3\n",
    "        temporal_flag = temporal_flag.map({1: 'WinterHalf', 2: 'SummerHalf', 3: 'SummerHalf', 4: 'WinterHalf'})\n",
    "    elif temp_subset == 'Season':\n",
    "        temporal_flag = (valid_dates.month%12 + 3)//3\n",
    "        temporal_flag = temporal_flag.map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Autumn'})\n",
    "    elif temp_subset == 'Month':\n",
    "        temporal_flag = valid_dates.month.astype(str)\n",
    "    elif temp_subset == 'DayMonth':\n",
    "        temporal_flag = pd.Series([i[-4:] for i in valid_dates.strftime('%Y%m%d')])\n",
    "        temporal_flag = temporal_flag.values\n",
    "        \n",
    "    return temporal_flag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for start & end of Summer Half (Summer Half between 16th April - 15th October, inclusive of both dates)\n",
    "# this is based on the climatological frequencies of the Mediterranean patterns\n",
    "sorted_dates = np.array(pd.date_range('20040101', '20041231').strftime('%m%d')) # leap year for getting all dates\n",
    "start_summerhalf = np.where(sorted_dates=='0416')[0]\n",
    "end_summerhalf = np.where(sorted_dates=='1015')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clim_freqs(dataset):\n",
    "    \n",
    "    freqs = [(dataset==i_cl).mean('time') for i_cl in range(cl_max+1)]\n",
    "    freqs = xr.concat(freqs, dim=pd.Index(range(cl_max+1), name='cluster'))\n",
    "    \n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daymonthfreqs(input_data):\n",
    "    \n",
    "    dataset, daymonth_used = input_data\n",
    "     \n",
    "    dates_used = all_dates_atm_var_extd[all_dates_atm_var_extd.strftime('%m%d').isin([daymonth_used])]\n",
    "\n",
    "    # add buffer days (before/after) for having a more robust climatology for mean and std\n",
    "    all_dates_used = [pd.date_range(i_date-pd.DateOffset(days=offset_days), \n",
    "                                    i_date+pd.DateOffset(days=offset_days), freq='D') \n",
    "                      for i_date in dates_used]\n",
    "    all_dates_used = np.array([j for i in all_dates_used for j in i]) # flatten data to have 1-d array\n",
    "    all_dates_used = all_dates_used[pd.to_datetime(all_dates_used).isin(all_dates_atm_var)] # existing dates\n",
    "\n",
    "    # keep all dates of interest and get climatology\n",
    "    clim_mean = dataset.sel(time=all_dates_used)\n",
    "        \n",
    "    clim_freq_i_date = clim_freqs(clim_mean) # get clim frequencies of the subset of interest\n",
    "\n",
    "    return clim_freq_i_date.assign_coords({'time': daymonth_used})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 366/366 [00:07<00:00, 46.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# get climatological frequencies (for DayMonth and considering All data)\n",
    "all_dates_atm_var = pd.to_datetime(era5_med.time.values)\n",
    "all_dates_atm_var_extd = pd.date_range(all_dates_atm_var[0] - pd.DateOffset(years=1), \n",
    "                                       all_dates_atm_var[-1] + pd.DateOffset(years=1))\n",
    "unique_daymonth = all_dates_atm_var.strftime('%m%d')\n",
    "unique_daymonth = sorted(set(unique_daymonth))\n",
    "\n",
    "pool = multiprocessing.Pool() # object for multiprocessing\n",
    "era5_freqs = list(tqdm.tqdm(pool.imap(daymonthfreqs, [(era5_med, i) for i in unique_daymonth]), \n",
    "                            total=len(unique_daymonth), position=0, leave=True))\n",
    "pool.close()\n",
    "era5_freqs = xr.concat(era5_freqs, dim='time')\n",
    "\n",
    "era5_freqs = xr.concat([clim_freqs(era5_med).assign_coords({'time': 'All'}), era5_freqs], dim='time') # all data\n",
    "era5_freqs = era5_freqs.expand_dims({'clim_type': frcsts_med.clim_type.values}) # expand for same dims are frcsts\n",
    "\n",
    "del(pool, all_dates_atm_var, all_dates_atm_var_extd, unique_daymonth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(dates_used):\n",
    "    \n",
    "    observations_raw = era5_lead_all.sel(time=dates_used) # keep only common dates\n",
    "    forecasts_raw = frcst_lead_all.sel(time=dates_used).drop('step') # keep only common dates\n",
    "   \n",
    "    # convert era5 and forecasts to boolean for each cluster\n",
    "    observ = xr.concat([observations_raw==i_cl for i_cl in cl_all], dim=pd.Index(cl_all, name='cluster'))*1\n",
    "    forecasts = xr.concat([forecasts_raw==i_cl for i_cl in cl_all], dim=pd.Index(cl_all, name='cluster'))*1 \n",
    "\n",
    "    # generate reference forecasts\n",
    "    ref_frcst_1 = era5_freqs.sel(time=['All']*len(observ.time))\n",
    "    ref_frcst_1 = ref_frcst_1.assign_coords({'time': observ.time.values})\n",
    "\n",
    "    ref_frcst_2 = era5_freqs.sel(time=temp_flagging(observ.time.values, 'DayMonth'))\n",
    "    ref_frcst_2 = ref_frcst_2.assign_coords({'time': observ.time.values})\n",
    "           \n",
    "    # get brier score\n",
    "    dim_name = pd.Index(['frcst_fair', 'frcst', 'ref1', 'ref2'], name='forecast_type')\n",
    "    brier_ref1_all = ((observ-ref_frcst_1)**2) # calculate brier score of ref forecast 1\n",
    "    brier_ref2_all = ((observ-ref_frcst_2)**2) # calculate brier score of ref forecast 2\n",
    "    brier_frcst_all = ((observ-forecasts.mean('number'))**2) # calculate brier score of forecasts\n",
    "    n_members = len(forecasts.number.values)\n",
    "    correct_counts = (forecasts==observ).sum('number').where(observ).sum('cluster')\n",
    "    fair_adjustment_all = correct_counts*(n_members-correct_counts)/n_members**2/(n_members-1)\n",
    "    fair_brier_frcst_all = brier_frcst_all - fair_adjustment_all\n",
    "    \n",
    "    all_months = list(range(1,13))\n",
    "    winter_months = [1,2,9,10,11,12]\n",
    "    summer_months = [3,4,5,6,7,8]\n",
    "    \n",
    "    brier_all = []\n",
    "    for i_mon, i_season in zip([all_months, winter_months, summer_months], ['All', 'Winter', 'Summer']):\n",
    "        i_dates_kept = pd.to_datetime(observ.time.values).month.isin(i_mon)\n",
    "        brier_ref1 = brier_ref1_all.isel(time=i_dates_kept).mean('time')\n",
    "        brier_ref2 = brier_ref2_all.isel(time=i_dates_kept).mean('time')\n",
    "        brier_frcst = brier_frcst_all.isel(time=i_dates_kept).mean('time')\n",
    "        fair_brier_frcst = fair_brier_frcst_all.isel(time=i_dates_kept).mean('time')\n",
    "\n",
    "        brier_season = [fair_brier_frcst, brier_frcst, brier_ref1, brier_ref2]\n",
    "        brier_season = xr.concat(brier_season, dim=dim_name).assign_coords({'Season': i_season})\n",
    "        brier_all.append(brier_season)\n",
    "        \n",
    "    brier_all = xr.concat(brier_all, dim='Season')\n",
    "    brier_all.name = 'BS'\n",
    "    \n",
    "    # get brier skill score\n",
    "    brier_ref_min = brier_all.sel(forecast_type=['ref1', 'ref2']).min('forecast_type')\n",
    "    brier_skill_all = 1-brier_all/brier_ref_min\n",
    "    brier_skill_all.name = 'BSS'\n",
    "    \n",
    "    brier_all = xr.merge([brier_all, brier_skill_all]) # combine brier score and brier skill score\n",
    "    \n",
    "    # calculate aggregated brier results and combine with the cluster-specific results\n",
    "    instances_all = observ.sum('time') # count total instances of each cluster at observations\n",
    "    brier_all_mean = brier_all.weighted(instances_all).mean('cluster').assign_coords({'cluster': -1})\n",
    "    brier_all = xr.concat([brier_all_mean, brier_all], dim='cluster')\n",
    "\n",
    "    return brier_all    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score_bootstrap(lead_used):\n",
    "    \n",
    "    global era5_lead_all, frcst_lead_all, step_used # global variables for using on functions\n",
    "    step_used = lead_used\n",
    "    era5_lead_all = era5\n",
    "    frcst_lead_all = frcst.sel(step=lead_used) # subset lead day of interest for forecasts\n",
    "    # convert the time (which is initiation time) to the actual valid time, for proper comparison with obs.\n",
    "    frcst_lead_all = frcst_lead_all.assign_coords({'time': frcst_lead_all.time+np.timedelta64(step_used, 'D')})\n",
    "\n",
    "    common_dates = set(frcst_lead_all.time.values) & set(era5_lead_all.time.values) # get common dates\n",
    "    common_dates = sorted(common_dates) # convert to sorted listed\n",
    "    common_dates = pd.to_datetime(common_dates)\n",
    "    summer = common_dates[common_dates.month.isin([3,4,5,6,7,8])]\n",
    "    winter = common_dates[common_dates.month.isin([1,2,9,10,11,12])]\n",
    "    \n",
    "    # generate bootstrap dates, with same number of winter/summer for all subsets for getting also seasonal stats\n",
    "    bbs_dates = []\n",
    "    for i_season in [winter, summer]:\n",
    "        np.random.seed(10)\n",
    "        bbs_i_season = np.random.choice(i_season, len(i_season)*bootstr) # generate all bootstrap dates\n",
    "        bbs_i_season = np.array_split(bbs_i_season, bootstr) # split into number of subsets (samples)\n",
    "        bbs_i_season = np.insert(np.array(bbs_i_season), 0, np.array(i_season), axis=0) # add actual at 1 place\n",
    "        bbs_dates.append(bbs_i_season)\n",
    "\n",
    "    final_bbs_dates = []\n",
    "    for i_bss in range(bootstr+1): # +1 because the original dates are appended before\n",
    "        i_dates = np.concatenate((bbs_dates[0][i_bss], bbs_dates[1][i_bss]))\n",
    "        final_bbs_dates.append(sorted(i_dates))\n",
    "    \n",
    "    brier_score_all_bootstraps = [brier_score(i_dates) for i_dates in final_bbs_dates]\n",
    "    bootstrap_dim = pd.Index(range(bootstr+1), name='bootstrap')\n",
    "    brier_score_all_bootstraps = xr.concat(brier_score_all_bootstraps, dim=bootstrap_dim)\n",
    "    \n",
    "    # process bootstraps for getting the results from the Q5, Q95, Median, and Actual bootstraps\n",
    "    data_final = brier_score_all_bootstraps.to_array().rename({'variable': 'Indicator'})\n",
    "    data_final = data_final.transpose(..., 'bootstrap')\n",
    "    \n",
    "    # get percent of bootstraps that BSS is positive (for checking significance of results)\n",
    "    sign = (data_final.sel(Indicator='BSS')>0).sum('bootstrap')/(bootstr+1)\n",
    "    sign = sign.expand_dims('Indicator').to_dataset('Indicator')\n",
    "    sign = sign.rename({'BSS': 'BSS_Sign'})\n",
    "    \n",
    "    # get the quantiles of interest based on bootstraps\n",
    "    data_quant = np.sort(data_final.isel(bootstrap=data_final.bootstrap>0), axis=-1)[..., [l_min, l_max]]\n",
    "    data_quant = data_final.sel(bootstrap=range(2))*0+data_quant\n",
    "    data_quant = data_quant.assign_coords({'bootstrap': ['Q5', 'Q95']})\n",
    "\n",
    "    # add results from original analysis\n",
    "    data_actual = data_final.isel(bootstrap=0).assign_coords({'bootstrap': 'Actual'})\n",
    "\n",
    "    # get median value based on bootstraps and actual data (so median is actual sorted index)\n",
    "    data_median = np.sort(data_final, axis=-1)[..., l_med]\n",
    "    data_median = data_final.sel(bootstrap=0)*0+data_median\n",
    "    data_median = data_median.assign_coords({'bootstrap': 'Q50'})\n",
    "\n",
    "    data_final = xr.concat([data_quant, data_actual, data_median], dim='bootstrap')\n",
    "    data_final = data_final.to_dataset('Indicator')\n",
    "    \n",
    "    data_final = xr.merge([data_final, sign])\n",
    "    \n",
    "    del(era5_lead_all, frcst_lead_all, step_used)\n",
    "    \n",
    "    return data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 44/44 [43:49<00:00, 59.75s/it]\n"
     ]
    }
   ],
   "source": [
    "frcst = frcsts_med.isel(number=(frcsts_med.number.values>=0))\n",
    "frcst = frcst.assign_coords({'step': (frcst.step.values/np.timedelta64(1, 'D')).astype(int)})\n",
    "steps_all = frcst.step.values\n",
    "era5 = era5_med\n",
    "\n",
    "pool = multiprocessing.Pool() # object for multiprocessing\n",
    "bs_final = list(tqdm.tqdm(pool.imap(brier_score_bootstrap, steps_all), \n",
    "                          total=len(steps_all), position=0, leave=True))\n",
    "pool.close()\n",
    "bs_final = xr.concat(bs_final, dim=pd.Index(steps_all, name='step'))\n",
    "del(pool)\n",
    "\n",
    "bs_final.to_netcdf(out_dir+'Med_LocalizedPatterns_ForecastingBrier.nc')\n",
    "del(frcst, steps_all, era5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
